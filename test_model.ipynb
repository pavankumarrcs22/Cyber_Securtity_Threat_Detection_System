{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdf53e45-ba2a-495b-b45a-955a1ef37ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Predictions: [2 1 1 4 1 1 1 1 4 1 1 4 4 1 1]\n",
      "[1] Predictions: [4 4 1 1 1 1 4 1 1 4 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 4 1 1 4 1 1 1 4 4 1 4 1 1]\n",
      "[1] Predictions: [1 4 4 1 1 1 1 3 1 1 4 1 1 1 1]\n",
      "[1] Predictions: [1 1 4 1 4 4 1 1 4 1 1 4 3 1 1]\n",
      "[1] Predictions: [1 1 1 4 1 1 1 2 4 4 1 1 3 1 4]\n",
      "[1] Predictions: [1 1 1 3 1 1 4 1 1 4 1 1 4 4 1]\n",
      "[1] Predictions: [4 4 1 3 1 1 1 1 1 1 1 1 4 1 1]\n",
      "[1] Predictions: [1 2 1 1 1 1 4 1 1 1 1 4 1 1 1]\n",
      "[1] Predictions: [1 4 4 4 2 1 1 2 1 1 1 1 1 1 4]\n",
      "[1] Predictions: [1 1 1 4 1 4 1 1 4 1 1 1 2 1 1]\n",
      "[1] Predictions: [1 1 4 1 1 1 1 1 1 1 1 1 4 1 2]\n",
      "[1] Predictions: [1 1 4 1 1 4 1 1 4 1 1 4 1 1 4]\n",
      "[1] Predictions: [2 1 1 4 1 1 2 1 1 1 4 1 4 1 4]\n",
      "[1] Predictions: [1 1 1 4 1 4 1 1 1 4 4 4 1 1 4]\n",
      "[1] Predictions: [1 4 1 1 1 1 1 1 4 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 4 4 1 4 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 4 4 4 1 1 1 1 4 4 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 4 1 1 1]\n",
      "[1] Predictions: [1 1 4 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 4 1 1 4]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[2] Predictions: [2 2 2 2 1 2 2 2 2 2 2 1 2 2 2]\n",
      "[2] Predictions: [4 2 2 2 4 2 1 2 2 2 2 2 2 2 1]\n",
      "[2] Predictions: [2 2 2 2 2 2 2 2 2 2 1 2 2 2 1]\n",
      "[2] Predictions: [2 2 4 2 2 2 1 2 4 2 1 2 4 2 2]\n",
      "[2] Predictions: [2 1 2 2 2 2 2 1 2 2 2 2 2 2 2]\n",
      "[2] Predictions: [2 2 2 2 2 1 2 2 2 1 2 2 4 2 1]\n",
      "[2] Predictions: [2 2 2 4 2 2 2 4 2 1 2 2 2 2 2]\n",
      "[2] Predictions: [1 2 2 2 2 2 2 2 2 2 2 2 4 2 2]\n",
      "[2] Predictions: [2 1 2 2 2 1 2 2 2 2 2 2 2 2 4]\n",
      "[2] Predictions: [2 2 2 1 2 2 2 1 2 4 2 2 2 2 2]\n",
      "[2] Predictions: [2 2 2 2 2 2 2 1 2 2 2 1 2 1 2]\n",
      "[2] Predictions: [2 2 2 1 2 4 2 4 2 1 2 1 2 2 2]\n",
      "[2] Predictions: [4 2 1 2 2 2 2 2 1 2 2 2 2 2 1]\n",
      "[3] Predictions: [1 1 3 3 1 2 1 3 1 1 3 3 3 3 3]\n",
      "[3] Predictions: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 1]\n",
      "[3] Predictions: [1 3 3 1 3 2 3 3 3 3 1 1 3 3 3]\n",
      "[3] Predictions: [3 3 3 3 3 4 3 3 3 3 3 3 3 3 3]\n",
      "[3] Predictions: [1 3 4 1 1 3 2 2 3 1 3 3 3 3 3]\n",
      "[3] Predictions: [3 3 3 3 3 3 3 3 1 3 3 3 3 3 3]\n",
      "[3] Predictions: [3 3 3 1 3 2 2 3 3 3 3 1 1 3 3]\n",
      "[3] Predictions: [3 3 3 3 3 3 3 3 3 3 3 1 3 3 3]\n",
      "[3] Predictions: [3 1 3 1 2 3 2 3 3 3 1 1 3 3 3]\n",
      "[3] Predictions: [3 3 3 3 3 3 3 3 3 3 3 4 1 3 3]\n",
      "[3] Predictions: [3 4 3 1 3 2 2 3 1 3 3 3 3 3 3]\n",
      "[3] Predictions: [3 3 3 3 3 3 3 3 1 3 3 3 3 3 3]\n",
      "[3] Predictions: [3 3 3 3 1 1 2 3 2 3 3 3 3 1 3]\n",
      "[3] Predictions: [3 3 1 3 2 3 1 3 3 3 3 3 3 3 3]\n",
      "[3] Predictions: [2 3 3 3 3 3 1 3 1 3 2 1 1 3 3]\n",
      "[3] Predictions: [3 3 3 3 3 3 3 3 3 2 3 3 1 3 3]\n",
      "[3] Predictions: [3 3 3 4 3 3 3 3 3 1 3 1 3 2 1]\n",
      "[3] Predictions: [1 3 3 1 3 1 3 3 3 3 3 3 3 3 3]\n",
      "[3] Predictions: [3 3 3 3 3 1 3 3 3 3 3 3 3 2 3]\n",
      "[3] Predictions: [1 1 3 3 2 3 3 1 1 3 3 3 3 3 1]\n",
      "[4] Predictions: [1 1 1 1 1 1 1 1 4 4 3 4 1 4 1]\n",
      "[4] Predictions: [3 1 2 4 1 1 1 4 1 1 1 1 1 1 4]\n",
      "[4] Predictions: [4 1 1 1 3 4 4 4 1 1 1 4 1 1 4]\n",
      "[4] Predictions: [1 1 4 1 2 2 4 1 4 4 4 4 4 1 4]\n",
      "[4] Predictions: [4 1 4 1 1 4 1 1 1 1 4 1 4 4 1]\n",
      "[4] Predictions: [3 4 4 1 1 1 4 4 1 1 1 1 1 1 1]\n",
      "[4] Predictions: [1 1 4 4 4 4 2 4 1 4 4 1 4 1 1]\n",
      "[4] Predictions: [4 1 1 1 1 4 1 4 4 4 4 4 4 1 4]\n",
      "[4] Predictions: [1 1 4 1 1 1 4 1 4 1 1 4 4 4 4]\n",
      "[4] Predictions: [2 1 4 4 1 4 1 1 4 1 1 1 1 4 1]\n",
      "[4] Predictions: [4 1 1 2 1 4 1 1 1 1 4 1 1 1 1]\n",
      "[4] Predictions: [1 4 1 1 4 1 4 2 1 4 4 1 4 1 1]\n",
      "[4] Predictions: [1 1 1 1 1 4 1 4 1 1 2 4 4 4 1]\n",
      "[4] Predictions: [4 1 1 1 1 1 1 4 1 4 1 1 4 4 4]\n",
      "[4] Predictions: [4 1 1 2 1 4 4 1 1 1 1 1 4 1 1]\n",
      "[4] Predictions: [4 1 4 1 1 1 1 2 1 4 1 4 1 1 1]\n",
      "[4] Predictions: [1 1 1 1 1 1 1 4 1 4 4 4 4 3 1]\n",
      "[4] Predictions: [4 4 1 4 1 1 1 1 1 1 1 1 1 4 1]\n",
      "[4] Predictions: [1 4 4 1 1 4 1 1 1 1 1 1 1 1 4]\n",
      "[4] Predictions: [1 1 1 1 1 4 1 1 4 1 4 1 1 1 1]\n",
      "[4] Predictions: [1 1 1 1 1 1 1 1 4 1 1 1 1 1 1]\n",
      "[4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[4] Predictions: [4 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import joblib  # For loading the trained model\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load preprocessed datasets\n",
    "attack_free = pd.read_csv('extracted feature/CAN_attack_dataset1/Attack_free new.csv')[0:500]\n",
    "dos = pd.read_csv('extracted feature/CAN_attack_dataset1/DoS_Attack_new.csv')[0:200]\n",
    "fuzzy = pd.read_csv('extracted feature/CAN_attack_dataset1/Fuzzy_Attack_New.csv')[0:300]\n",
    "impersonation = pd.read_csv('extracted feature/CAN_attack_dataset1/Impersonation_Attack_New.csv')[0:400]\n",
    "\n",
    "def preprocess_data(df):\n",
    "    label_encoder = LabelEncoder()\n",
    "    # Process all columns except (optionally) the first if it is not categorical\n",
    "    for col in df.columns[1:]:\n",
    "        df[col] = label_encoder.fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "# Apply preprocessing\n",
    "attack_free = preprocess_data(attack_free)\n",
    "dos = preprocess_data(dos)\n",
    "fuzzy = preprocess_data(fuzzy)\n",
    "impersonation = preprocess_data(impersonation)\n",
    "\n",
    "# Combine datasets\n",
    "datasets = [(attack_free, 1), (dos, 2), (fuzzy, 3), (impersonation, 4)]\n",
    "\n",
    "# Feature Scaling: **Include all columns**\n",
    "dataset_combined = np.vstack([df.values for df, _ in datasets])\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(dataset_combined)\n",
    "\n",
    "# Load the trained SVM model from the .pkl file\n",
    "model = joblib.load(\"svm_model.pkl\")  # This model expects 16 features\n",
    "\n",
    "def send_data_real_time(df, label, duration=15):\n",
    "    for i in range(0, len(df), 15):  # Send 15 rows at a time\n",
    "        if i + 15 > len(df):\n",
    "            break  # Stop if there are fewer than 15 rows left\n",
    "        batch = df.iloc[i:i+15, :].values  # Use all columns (16 features)\n",
    "        batch = scaler.transform(batch)     # Apply scaling\n",
    "        \n",
    "        # Check if the number of features matches the model's expected number\n",
    "        if batch.shape[1] != model.n_features_in_:\n",
    "            print(f\"Warning: Expected {model.n_features_in_} features, but got {batch.shape[1]} features.\")\n",
    "            continue  # Skip this batch if the number of features is incorrect\n",
    "        \n",
    "        predictions = model.predict(batch)  # Use the loaded model\n",
    "        print(f\"[{label}] Predictions: {predictions}\")\n",
    "        time.sleep(1)  # Wait for 1 second\n",
    "\n",
    "# Run testing for each dataset sequentially\n",
    "for df, label in datasets:\n",
    "    send_data_real_time(df, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f66e5153-5265-48e4-b677-6927dab4b623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset Label 1] Predictions: [2 1 1 4 1 1 1 1 4 1 1 4 4 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [4 4 1 1 1 1 4 1 1 4 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 4 1 1 4 1 1 1 4 4 1 4 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 4 4 1 1 1 1 3 1 1 4 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 4 1 4 4 1 1 4 1 1 4 3 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 4 1 1 1 2 4 4 1 1 3 1 4]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 3 1 1 4 1 1 4 1 1 4 4 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [4 4 1 3 1 1 1 1 1 1 1 1 4 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 2 1 1 1 1 4 1 1 1 1 4 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 4 4 4 2 1 1 2 1 1 1 1 1 1 4]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 4 1 4 1 1 4 1 1 1 2 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 4 1 1 1 1 1 1 1 1 1 4 1 2]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 4 1 1 4 1 1 4 1 1 4 1 1 4]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [2 1 1 4 1 1 2 1 1 1 4 1 4 1 4]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 4 1 4 1 1 1 4 4 4 1 1 4]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 4 1 1 1 1 1 1 4 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 4 4 1 4 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 4 4 4 1 1 1 1 4 4 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 4 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 4 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 4 1 1 4]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 2] Predictions: [2 2 2 2 1 2 2 2 2 2 2 1 2 2 2]\n",
      "-> Majority Vote: 2 (DoS)\n",
      "[Dataset Label 2] Predictions: [4 2 2 2 4 2 1 2 2 2 2 2 2 2 1]\n",
      "-> Majority Vote: 2 (DoS)\n",
      "[Dataset Label 2] Predictions: [2 2 2 2 2 2 2 2 2 2 1 2 2 2 1]\n",
      "-> Majority Vote: 2 (DoS)\n",
      "[Dataset Label 2] Predictions: [2 2 4 2 2 2 1 2 4 2 1 2 4 2 2]\n",
      "-> Majority Vote: 2 (DoS)\n",
      "[Dataset Label 2] Predictions: [2 1 2 2 2 2 2 1 2 2 2 2 2 2 2]\n",
      "-> Majority Vote: 2 (DoS)\n",
      "[Dataset Label 2] Predictions: [2 2 2 2 2 1 2 2 2 1 2 2 4 2 1]\n",
      "-> Majority Vote: 2 (DoS)\n",
      "[Dataset Label 2] Predictions: [2 2 2 4 2 2 2 4 2 1 2 2 2 2 2]\n",
      "-> Majority Vote: 2 (DoS)\n",
      "[Dataset Label 2] Predictions: [1 2 2 2 2 2 2 2 2 2 2 2 4 2 2]\n",
      "-> Majority Vote: 2 (DoS)\n",
      "[Dataset Label 2] Predictions: [2 1 2 2 2 1 2 2 2 2 2 2 2 2 4]\n",
      "-> Majority Vote: 2 (DoS)\n",
      "[Dataset Label 2] Predictions: [2 2 2 1 2 2 2 1 2 4 2 2 2 2 2]\n",
      "-> Majority Vote: 2 (DoS)\n",
      "[Dataset Label 2] Predictions: [2 2 2 2 2 2 2 1 2 2 2 1 2 1 2]\n",
      "-> Majority Vote: 2 (DoS)\n",
      "[Dataset Label 2] Predictions: [2 2 2 1 2 4 2 4 2 1 2 1 2 2 2]\n",
      "-> Majority Vote: 2 (DoS)\n",
      "[Dataset Label 2] Predictions: [4 2 1 2 2 2 2 2 1 2 2 2 2 2 1]\n",
      "-> Majority Vote: 2 (DoS)\n",
      "[Dataset Label 3] Predictions: [1 1 3 3 1 2 1 3 1 1 3 3 3 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 1]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [1 3 3 1 3 2 3 3 3 3 1 1 3 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 3 3 3 4 3 3 3 3 3 3 3 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [1 3 4 1 1 3 2 2 3 1 3 3 3 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 3 3 3 3 3 3 1 3 3 3 3 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 3 1 3 2 2 3 3 3 3 1 1 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 3 3 3 3 3 3 3 3 3 1 3 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 1 3 1 2 3 2 3 3 3 1 1 3 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 3 3 3 3 3 3 3 3 3 4 1 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 4 3 1 3 2 2 3 1 3 3 3 3 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 3 3 3 3 3 3 1 3 3 3 3 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 3 3 1 1 2 3 2 3 3 3 3 1 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 1 3 2 3 1 3 3 3 3 3 3 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [2 3 3 3 3 3 1 3 1 3 2 1 1 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 3 3 3 3 3 3 3 2 3 3 1 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 3 4 3 3 3 3 3 1 3 1 3 2 1]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [1 3 3 1 3 1 3 3 3 3 3 3 3 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 3 3 3 1 3 3 3 3 3 3 3 2 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [1 1 3 3 2 3 3 1 1 3 3 3 3 3 1]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 4] Predictions: [1 1 1 1 1 1 1 1 4 4 3 4 1 4 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [3 1 2 4 1 1 1 4 1 1 1 1 1 1 4]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [4 1 1 1 3 4 4 4 1 1 1 4 1 1 4]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 4 1 2 2 4 1 4 4 4 4 4 1 4]\n",
      "-> Majority Vote: 4 (Impersonation)\n",
      "[Dataset Label 4] Predictions: [4 1 4 1 1 4 1 1 1 1 4 1 4 4 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [3 4 4 1 1 1 4 4 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 4 4 4 4 2 4 1 4 4 1 4 1 1]\n",
      "-> Majority Vote: 4 (Impersonation)\n",
      "[Dataset Label 4] Predictions: [4 1 1 1 1 4 1 4 4 4 4 4 4 1 4]\n",
      "-> Majority Vote: 4 (Impersonation)\n",
      "[Dataset Label 4] Predictions: [1 1 4 1 1 1 4 1 4 1 1 4 4 4 4]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [2 1 4 4 1 4 1 1 4 1 1 1 1 4 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [4 1 1 2 1 4 1 1 1 1 4 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 4 1 1 4 1 4 2 1 4 4 1 4 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 1 1 1 4 1 4 1 1 2 4 4 4 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [4 1 1 1 1 1 1 4 1 4 1 1 4 4 4]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [4 1 1 2 1 4 4 1 1 1 1 1 4 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [4 1 4 1 1 1 1 2 1 4 1 4 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 1 1 1 1 1 4 1 4 4 4 4 3 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [4 4 1 4 1 1 1 1 1 1 1 1 1 4 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 4 4 1 1 4 1 1 1 1 1 1 1 1 4]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 1 1 1 4 1 1 4 1 4 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 1 1 1 1 1 1 4 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [4 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import joblib  # For loading the trained model\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load preprocessed datasets (example with limited rows)\n",
    "attack_free = pd.read_csv('extracted feature/CAN_attack_dataset1/Attack_free new.csv')[0:500]\n",
    "dos = pd.read_csv('extracted feature/CAN_attack_dataset1/DoS_Attack_new.csv')[0:200]\n",
    "fuzzy = pd.read_csv('extracted feature/CAN_attack_dataset1/Fuzzy_Attack_New.csv')[0:300]\n",
    "impersonation = pd.read_csv('extracted feature/CAN_attack_dataset1/Impersonation_Attack_New.csv')[0:400]\n",
    "\n",
    "def preprocess_data(df):\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in df.columns[1:]:  # Assuming first column is timestamp or ID\n",
    "        df[col] = label_encoder.fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "# Apply preprocessing\n",
    "attack_free = preprocess_data(attack_free)\n",
    "dos = preprocess_data(dos)\n",
    "fuzzy = preprocess_data(fuzzy)\n",
    "impersonation = preprocess_data(impersonation)\n",
    "\n",
    "# Combine datasets with a dataset label for reference\n",
    "datasets = [(attack_free, 1), (dos, 2), (fuzzy, 3), (impersonation, 4)]\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "# Note: Adjust here if you want to include or exclude the first column. \n",
    "# For example, if the first column is not a feature, use df.iloc[:, 1:]\n",
    "dataset_combined = np.vstack([df.values for df, _ in datasets])\n",
    "scaler.fit(dataset_combined)\n",
    "\n",
    "# Load the trained SVM model from the .pkl file\n",
    "model = joblib.load(\"svm_model.pkl\")  # The model should expect the same number of features as scaler was fit on\n",
    "\n",
    "# Mapping from numeric prediction to attack type\n",
    "attack_mapping = {\n",
    "    1: \"Attack Free\",\n",
    "    2: \"DoS\",\n",
    "    3: \"Fuzzy\",\n",
    "    4: \"Impersonation\"\n",
    "}\n",
    "\n",
    "def get_majority_label(predictions):\n",
    "    \"\"\"\n",
    "    Given an array of predictions, determine the majority label.\n",
    "    \"\"\"\n",
    "    unique, counts = np.unique(predictions, return_counts=True)\n",
    "    max_index = np.argmax(counts)\n",
    "    majority_label = unique[max_index]\n",
    "    return majority_label\n",
    "\n",
    "def send_data_real_time(df, label, duration=15):\n",
    "    for i in range(0, len(df), 15):  # Send 15 rows at a time\n",
    "        if i + 15 > len(df):\n",
    "            break  # Stop if there are fewer than 15 rows left\n",
    "            \n",
    "        # Adjust this slice if you need to drop a column (e.g., timestamp/ID)\n",
    "        batch = df.iloc[i:i+15, :].values  \n",
    "        batch = scaler.transform(batch)  # Apply scaling\n",
    "        \n",
    "        # Check if the number of features matches the model's expected number\n",
    "        if batch.shape[1] != model.n_features_in_:\n",
    "            print(f\"Warning: Expected {model.n_features_in_} features, but got {batch.shape[1]} features.\")\n",
    "            continue  # Skip this batch if the number of features is incorrect\n",
    "        \n",
    "        predictions = model.predict(batch)  # Get predictions for the batch\n",
    "        \n",
    "        # Determine the majority class in the batch\n",
    "        majority_label = get_majority_label(predictions)\n",
    "        attack_type = attack_mapping.get(majority_label, \"Unknown\")\n",
    "        \n",
    "        print(f\"[Dataset Label {label}] Predictions: {predictions}\")\n",
    "        print(f\"-> Majority Vote: {majority_label} ({attack_type})\")\n",
    "        time.sleep(1)  # Wait for 1 second\n",
    "\n",
    "# Run testing for each dataset sequentially\n",
    "for df, label in datasets:\n",
    "    send_data_real_time(df, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43ef94ed-1f5f-4bec-9ad5-291cb50ed955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Predictions: [1 4 1 3 1 2 1 1 3 2 1 2 2 2 4]\n",
      "[1] Predictions: [4 1 1 1 1 1 1 4 4 3 1 4 2 1 3]\n",
      "[1] Predictions: [2 1 2 2 4 2 2 2 1 3 1 4 1 1 1]\n",
      "[1] Predictions: [1 1 3 4 1 1 1 2 2 4 4 1 1 1 2]\n",
      "[1] Predictions: [1 1 1 4 4 3 1 2 3 4 1 2 2 2 4]\n",
      "[1] Predictions: [2 4 1 3 1 2 1 1 1 4 1 1 2 1 3]\n",
      "[1] Predictions: [2 4 1 2 2 4 4 1 1 2 1 4 1 1 4]\n",
      "[1] Predictions: [4 4 1 2 1 3 2 2 2 4 1 2 2 2 2]\n",
      "[1] Predictions: [1 1 2 1 1 4 3 1 1 1 1 3 2 2 2]\n",
      "[1] Predictions: [4 2 1 1 4 2 1 1 4 2 1 1 4 4 3]\n",
      "[1] Predictions: [1 1 1 3 1 2 2 4 2 2 2 1 1 2 1]\n",
      "[1] Predictions: [1 4 3 1 1 2 1 1 3 1 2 4 2 1 1]\n",
      "[1] Predictions: [4 2 1 1 4 4 1 1 1 2 3 4 1 2 2]\n",
      "[1] Predictions: [1 2 4 2 2 2 1 4 1 2 1 1 3 1 1]\n",
      "[1] Predictions: [2 1 1 3 1 2 2 4 4 4 4 1 4 4 3]\n",
      "[1] Predictions: [2 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[2] Predictions: [4 4 1 4 4 4 4 1 4 4 4 2 4 4 4]\n",
      "[2] Predictions: [1 4 3 4 1 4 4 4 2 4 2 4 4 4 2]\n",
      "[2] Predictions: [4 4 1 4 1 4 4 4 4 4 1 4 3 4 4]\n",
      "[2] Predictions: [4 4 4 4 4 4 2 4 1 4 3 4 1 4 4]\n",
      "[2] Predictions: [4 4 4 2 4 4 4 2 4 2 4 4 1 4 1]\n",
      "[2] Predictions: [4 4 4 4 4 1 4 3 4 4 4 4 4 4 2]\n",
      "[2] Predictions: [4 4 4 1 4 3 4 1 4 4 4 2 4 4 4]\n",
      "[2] Predictions: [2 4 2 4 4 4 4 4 1 4 4 4 1 4 4]\n",
      "[2] Predictions: [4 1 4 3 4 4 4 4 1 4 4 4 4 4 1]\n",
      "[2] Predictions: [4 4 4 4 4 4 4 2 4 1 4 3 4 2 4]\n",
      "[2] Predictions: [1 4 4 4 4 4 4 1 4 3 4 4 4 1 4]\n",
      "[2] Predictions: [3 4 4 1 4 4 4 1 4 4 4 2 4 4 4]\n",
      "[2] Predictions: [1 4 3 4 2 4 4 4 2 4 1 4 4 4 4]\n",
      "[3] Predictions: [3 3 3 3 3 1 3 3 2 4 3 3 3 3 3]\n",
      "[3] Predictions: [3 3 4 3 3 3 3 3 4 3 3 4 3 3 3]\n",
      "[3] Predictions: [3 3 3 3 3 1 3 3 3 3 2 4 3 3 3]\n",
      "[3] Predictions: [3 3 3 3 3 2 3 4 3 3 3 3 3 4 3]\n",
      "[3] Predictions: [3 3 2 4 3 3 3 1 3 3 3 3 3 3 3]\n",
      "[3] Predictions: [3 3 3 2 3 3 3 3 4 3 3 3 3 4 3]\n",
      "[3] Predictions: [3 3 3 3 3 3 1 3 3 3 3 2 4 3 3]\n",
      "[3] Predictions: [3 3 3 3 3 3 3 3 4 3 3 2 3 3 4]\n",
      "[3] Predictions: [3 3 3 3 1 3 3 3 3 3 2 4 3 3 3]\n",
      "[3] Predictions: [3 3 3 4 3 3 3 3 3 3 3 2 2 3 3]\n",
      "[3] Predictions: [3 2 3 4 3 2 1 3 4 3 3 3 3 3 3]\n",
      "[3] Predictions: [3 2 3 3 2 3 3 3 4 3 3 2 3 3 2]\n",
      "[3] Predictions: [3 4 3 3 2 4 1 3 2 2 3 3 3 4 3]\n",
      "[3] Predictions: [3 3 3 3 2 3 2 3 3 3 3 3 3 2 3]\n",
      "[3] Predictions: [2 3 2 3 3 3 2 3 4 3 2 1 3 3 3]\n",
      "[3] Predictions: [3 2 3 3 3 3 1 1 1 1 1 1 1 1 1]\n",
      "[3] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[3] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[3] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[3] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[4] Predictions: [1 1 1 1 2 4 2 1 3 2 4 4 3 1 1]\n",
      "[4] Predictions: [1 4 4 2 2 1 1 3 4 1 1 1 3 1 2]\n",
      "[4] Predictions: [3 2 4 2 1 4 2 1 1 2 1 3 1 1 2]\n",
      "[4] Predictions: [1 1 3 4 2 4 2 2 4 2 2 4 1 4 4]\n",
      "[4] Predictions: [2 1 3 1 2 1 1 1 2 4 2 1 3 2 2]\n",
      "[4] Predictions: [1 4 2 1 1 2 1 3 1 1 1 2 4 2 1]\n",
      "[4] Predictions: [4 4 3 2 2 4 2 1 4 4 2 1 3 1 2]\n",
      "[4] Predictions: [1 1 1 2 4 2 1 3 2 2 1 4 2 1 3]\n",
      "[4] Predictions: [1 2 1 1 1 1 2 1 3 2 4 2 2 4 2]\n",
      "[4] Predictions: [1 4 4 2 1 3 1 2 1 1 1 2 4 2 1]\n",
      "[4] Predictions: [3 3 2 1 4 2 1 1 2 1 3 1 1 2 1]\n",
      "[4] Predictions: [1 3 2 4 2 3 4 1 4 4 2 1 3 1 2]\n",
      "[4] Predictions: [1 1 1 2 4 2 1 3 3 2 1 4 2 2 1]\n",
      "[4] Predictions: [3 1 2 1 1 1 1 2 1 3 2 4 2 4 4]\n",
      "[4] Predictions: [1 1 3 1 4 4 2 2 1 1 2 1 3 1 1]\n",
      "[4] Predictions: [2 1 3 2 4 3 1 1 1 1 1 1 1 1 1]\n",
      "[4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#lets same check for dt_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import joblib  # For loading the trained model\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load preprocessed datasets\n",
    "attack_free = pd.read_csv('extracted feature/CAN_attack_dataset1/Attack_free new.csv')[0:500]\n",
    "dos = pd.read_csv('extracted feature/CAN_attack_dataset1/DoS_Attack_new.csv')[0:200]\n",
    "fuzzy = pd.read_csv('extracted feature/CAN_attack_dataset1/Fuzzy_Attack_New.csv')[0:300]\n",
    "impersonation = pd.read_csv('extracted feature/CAN_attack_dataset1/Impersonation_Attack_New.csv')[0:400]\n",
    "\n",
    "def preprocess_data(df):\n",
    "    label_encoder = LabelEncoder()\n",
    "    # Process all columns except (optionally) the first if it is not categorical\n",
    "    for col in df.columns[1:]:\n",
    "        df[col] = label_encoder.fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "# Apply preprocessing\n",
    "attack_free = preprocess_data(attack_free)\n",
    "dos = preprocess_data(dos)\n",
    "fuzzy = preprocess_data(fuzzy)\n",
    "impersonation = preprocess_data(impersonation)\n",
    "\n",
    "# Combine datasets\n",
    "datasets = [(attack_free, 1), (dos, 2), (fuzzy, 3), (impersonation, 4)]\n",
    "\n",
    "# Feature Scaling: **Include all columns**\n",
    "dataset_combined = np.vstack([df.values for df, _ in datasets])\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(dataset_combined)\n",
    "\n",
    "# Load the trained SVM model from the .pkl file\n",
    "model = joblib.load(\"dt_model.pkl\")  # This model expects 16 features\n",
    "\n",
    "def send_data_real_time(df, label, duration=15):\n",
    "    for i in range(0, len(df), 15):  # Send 15 rows at a time\n",
    "        if i + 15 > len(df):\n",
    "            break  # Stop if there are fewer than 15 rows left\n",
    "        batch = df.iloc[i:i+15, :].values  # Use all columns (16 features)\n",
    "        batch = scaler.transform(batch)     # Apply scaling\n",
    "        \n",
    "        # Check if the number of features matches the model's expected number\n",
    "        if batch.shape[1] != model.n_features_in_:\n",
    "            print(f\"Warning: Expected {model.n_features_in_} features, but got {batch.shape[1]} features.\")\n",
    "            continue  # Skip this batch if the number of features is incorrect\n",
    "        \n",
    "        predictions = model.predict(batch)  # Use the loaded model\n",
    "        print(f\"[{label}] Predictions: {predictions}\")\n",
    "        time.sleep(1)  # Wait for 1 second\n",
    "\n",
    "# Run testing for each dataset sequentially\n",
    "for df, label in datasets:\n",
    "    send_data_real_time(df, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34e07697-9973-406b-b258-00def1608433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset Label 1] Predictions: [1 4 1 3 1 2 1 1 3 2 1 2 2 2 4]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [4 1 1 1 1 1 1 4 4 3 1 4 2 1 3]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [2 1 2 2 4 2 2 2 1 3 1 4 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 3 4 1 1 1 2 2 4 4 1 1 1 2]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 4 4 3 1 2 3 4 1 2 2 2 4]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [2 4 1 3 1 2 1 1 1 4 1 1 2 1 3]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [2 4 1 2 2 4 4 1 1 2 1 4 1 1 4]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [4 4 1 2 1 3 2 2 2 4 1 2 2 2 2]\n",
      "-> Majority Vote: 2 (DoS)\n",
      "[Dataset Label 1] Predictions: [1 1 2 1 1 4 3 1 1 1 1 3 2 2 2]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [4 2 1 1 4 2 1 1 4 2 1 1 4 4 3]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 3 1 2 2 4 2 2 2 1 1 2 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 4 3 1 1 2 1 1 3 1 2 4 2 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [4 2 1 1 4 4 1 1 1 2 3 4 1 2 2]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 2 4 2 2 2 1 4 1 2 1 1 3 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [2 1 1 3 1 2 2 4 4 4 4 1 4 4 3]\n",
      "-> Majority Vote: 4 (Impersonation)\n",
      "[Dataset Label 1] Predictions: [2 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 1] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 2] Predictions: [4 4 1 4 4 4 4 1 4 4 4 2 4 4 4]\n",
      "-> Majority Vote: 4 (Impersonation)\n",
      "[Dataset Label 2] Predictions: [1 4 3 4 1 4 4 4 2 4 2 4 4 4 2]\n",
      "-> Majority Vote: 4 (Impersonation)\n",
      "[Dataset Label 2] Predictions: [4 4 1 4 1 4 4 4 4 4 1 4 3 4 4]\n",
      "-> Majority Vote: 4 (Impersonation)\n",
      "[Dataset Label 2] Predictions: [4 4 4 4 4 4 2 4 1 4 3 4 1 4 4]\n",
      "-> Majority Vote: 4 (Impersonation)\n",
      "[Dataset Label 2] Predictions: [4 4 4 2 4 4 4 2 4 2 4 4 1 4 1]\n",
      "-> Majority Vote: 4 (Impersonation)\n",
      "[Dataset Label 2] Predictions: [4 4 4 4 4 1 4 3 4 4 4 4 4 4 2]\n",
      "-> Majority Vote: 4 (Impersonation)\n",
      "[Dataset Label 2] Predictions: [4 4 4 1 4 3 4 1 4 4 4 2 4 4 4]\n",
      "-> Majority Vote: 4 (Impersonation)\n",
      "[Dataset Label 2] Predictions: [2 4 2 4 4 4 4 4 1 4 4 4 1 4 4]\n",
      "-> Majority Vote: 4 (Impersonation)\n",
      "[Dataset Label 2] Predictions: [4 1 4 3 4 4 4 4 1 4 4 4 4 4 1]\n",
      "-> Majority Vote: 4 (Impersonation)\n",
      "[Dataset Label 2] Predictions: [4 4 4 4 4 4 4 2 4 1 4 3 4 2 4]\n",
      "-> Majority Vote: 4 (Impersonation)\n",
      "[Dataset Label 2] Predictions: [1 4 4 4 4 4 4 1 4 3 4 4 4 1 4]\n",
      "-> Majority Vote: 4 (Impersonation)\n",
      "[Dataset Label 2] Predictions: [3 4 4 1 4 4 4 1 4 4 4 2 4 4 4]\n",
      "-> Majority Vote: 4 (Impersonation)\n",
      "[Dataset Label 2] Predictions: [1 4 3 4 2 4 4 4 2 4 1 4 4 4 4]\n",
      "-> Majority Vote: 4 (Impersonation)\n",
      "[Dataset Label 3] Predictions: [3 3 3 3 3 1 3 3 2 4 3 3 3 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 4 3 3 3 3 3 4 3 3 4 3 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 3 3 3 1 3 3 3 3 2 4 3 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 3 3 3 2 3 4 3 3 3 3 3 4 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 2 4 3 3 3 1 3 3 3 3 3 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 3 2 3 3 3 3 4 3 3 3 3 4 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 3 3 3 3 1 3 3 3 3 2 4 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 3 3 3 3 3 3 4 3 3 2 3 3 4]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 3 3 1 3 3 3 3 3 2 4 3 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 3 4 3 3 3 3 3 3 3 2 2 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 2 3 4 3 2 1 3 4 3 3 3 3 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 2 3 3 2 3 3 3 4 3 3 2 3 3 2]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 4 3 3 2 4 1 3 2 2 3 3 3 4 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 3 3 3 2 3 2 3 3 3 3 3 3 2 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [2 3 2 3 3 3 2 3 4 3 2 1 3 3 3]\n",
      "-> Majority Vote: 3 (Fuzzy)\n",
      "[Dataset Label 3] Predictions: [3 2 3 3 3 3 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 3] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 3] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 3] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 3] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 1 1 2 4 2 1 3 2 4 4 3 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 4 4 2 2 1 1 3 4 1 1 1 3 1 2]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [3 2 4 2 1 4 2 1 1 2 1 3 1 1 2]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 3 4 2 4 2 2 4 2 2 4 1 4 4]\n",
      "-> Majority Vote: 4 (Impersonation)\n",
      "[Dataset Label 4] Predictions: [2 1 3 1 2 1 1 1 2 4 2 1 3 2 2]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 4 2 1 1 2 1 3 1 1 1 2 4 2 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [4 4 3 2 2 4 2 1 4 4 2 1 3 1 2]\n",
      "-> Majority Vote: 2 (DoS)\n",
      "[Dataset Label 4] Predictions: [1 1 1 2 4 2 1 3 2 2 1 4 2 1 3]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 2 1 1 1 1 2 1 3 2 4 2 2 4 2]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 4 4 2 1 3 1 2 1 1 1 2 4 2 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [3 3 2 1 4 2 1 1 2 1 3 1 1 2 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 3 2 4 2 3 4 1 4 4 2 1 3 1 2]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 1 2 4 2 1 3 3 2 1 4 2 2 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [3 1 2 1 1 1 1 2 1 3 2 4 2 4 4]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 3 1 4 4 2 2 1 1 2 1 3 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [2 1 3 2 4 3 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n",
      "[Dataset Label 4] Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "-> Majority Vote: 1 (Attack Free)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import joblib  # For loading the trained model\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load preprocessed datasets (example with limited rows)\n",
    "attack_free = pd.read_csv('extracted feature/CAN_attack_dataset1/Attack_free new.csv')[0:500]\n",
    "dos = pd.read_csv('extracted feature/CAN_attack_dataset1/DoS_Attack_new.csv')[0:200]\n",
    "fuzzy = pd.read_csv('extracted feature/CAN_attack_dataset1/Fuzzy_Attack_New.csv')[0:300]\n",
    "impersonation = pd.read_csv('extracted feature/CAN_attack_dataset1/Impersonation_Attack_New.csv')[0:400]\n",
    "\n",
    "def preprocess_data(df):\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in df.columns[1:]:  # Assuming first column is timestamp or ID\n",
    "        df[col] = label_encoder.fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "# Apply preprocessing\n",
    "attack_free = preprocess_data(attack_free)\n",
    "dos = preprocess_data(dos)\n",
    "fuzzy = preprocess_data(fuzzy)\n",
    "impersonation = preprocess_data(impersonation)\n",
    "\n",
    "# Combine datasets with a dataset label for reference\n",
    "datasets = [(attack_free, 1), (dos, 2), (fuzzy, 3), (impersonation, 4)]\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "# Note: Adjust here if you want to include or exclude the first column. \n",
    "# For example, if the first column is not a feature, use df.iloc[:, 1:]\n",
    "dataset_combined = np.vstack([df.values for df, _ in datasets])\n",
    "scaler.fit(dataset_combined)\n",
    "\n",
    "# Load the trained SVM model from the .pkl file\n",
    "model = joblib.load(\"dt_model.pkl\")  # The model should expect the same number of features as scaler was fit on\n",
    "\n",
    "# Mapping from numeric prediction to attack type\n",
    "attack_mapping = {\n",
    "    1: \"Attack Free\",\n",
    "    2: \"DoS\",\n",
    "    3: \"Fuzzy\",\n",
    "    4: \"Impersonation\"\n",
    "}\n",
    "\n",
    "def get_majority_label(predictions):\n",
    "    \"\"\"\n",
    "    Given an array of predictions, determine the majority label.\n",
    "    \"\"\"\n",
    "    unique, counts = np.unique(predictions, return_counts=True)\n",
    "    max_index = np.argmax(counts)\n",
    "    majority_label = unique[max_index]\n",
    "    return majority_label\n",
    "\n",
    "def send_data_real_time(df, label, duration=15):\n",
    "    for i in range(0, len(df), 15):  # Send 15 rows at a time\n",
    "        if i + 15 > len(df):\n",
    "            break  # Stop if there are fewer than 15 rows left\n",
    "            \n",
    "        # Adjust this slice if you need to drop a column (e.g., timestamp/ID)\n",
    "        batch = df.iloc[i:i+15, :].values  \n",
    "        batch = scaler.transform(batch)  # Apply scaling\n",
    "        \n",
    "        # Check if the number of features matches the model's expected number\n",
    "        if batch.shape[1] != model.n_features_in_:\n",
    "            print(f\"Warning: Expected {model.n_features_in_} features, but got {batch.shape[1]} features.\")\n",
    "            continue  # Skip this batch if the number of features is incorrect\n",
    "        \n",
    "        predictions = model.predict(batch)  # Get predictions for the batch\n",
    "        \n",
    "        # Determine the majority class in the batch\n",
    "        majority_label = get_majority_label(predictions)\n",
    "        attack_type = attack_mapping.get(majority_label, \"Unknown\")\n",
    "        \n",
    "        print(f\"[Dataset Label {label}] Predictions: {predictions}\")\n",
    "        print(f\"-> Majority Vote: {majority_label} ({attack_type})\")\n",
    "        time.sleep(1)  # Wait for 1 second\n",
    "\n",
    "# Run testing for each dataset sequentially\n",
    "for df, label in datasets:\n",
    "    send_data_real_time(df, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d53694-4592-4284-a48e-67b1ab85f537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
